{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo4yqmYIDJK4",
        "outputId": "e129c4aa-d2b0-4406-ab89-2967c246c35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import glob              # easy file searching\n",
        "from PIL import Image    # image loading\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "import math\n",
        "import os\n",
        "import torchvision as tv # data augmentation/loading utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.io\n",
        "import copy\n",
        "import time\n",
        "from tqdm.autonotebook import tqdm\n",
        "from tempfile import TemporaryDirectory"
      ],
      "metadata": {
        "id": "wK-DwamdjAc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a178796-f701-4042-97a0-5efdcf3f77c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8230967616de>:22: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "from easydict import EasyDict as edict\n",
        "__C = edict()\n",
        "__C.running_length = 10\n",
        "cfg = __C\n",
        "# __C.BATCH_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "HISTORY_LENGTH = 10\n",
        "PREDICTION_LENGTH = 5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)\n",
        "LEARNING_RATE = 0.3\n",
        "FRAME_SIZE = 25 # 25 frames from 250 frames per second\n",
        "FRAME_RATE = int(250/FRAME_SIZE)"
      ],
      "metadata": {
        "id": "T3PMkBlImuz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2154ea-7235-4d76-c888-344bf4380642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Traces_6DOF_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, path, transform=None, target_transform=None):\n",
        "    super().__init__()\n",
        "    # get filenames\n",
        "    self.files = glob.glob(path)[0]\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "\n",
        "    # load grayscale images\n",
        "    \n",
        "    self.data = np.array(scipy.io.loadmat(self.files)['MMs1'],dtype='float32')[::FRAME_RATE,:]\n",
        "    # normalization\n",
        "    self.data[:,0] = self.data[:,0]/6\n",
        "    self.data[:,1] = self.data[:,1]/4\n",
        "    self.data[:,2] = self.data[:,2]/6\n",
        "    self.data[:,3] = self.data[:,3]/180\n",
        "    self.data[:,4] = self.data[:,4]/90\n",
        "    self.data[:,5] = self.data[:,5]/90\n",
        "    # define your transform\n",
        "    # self.transform = tv.transforms.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)-(HISTORY_LENGTH+PREDICTION_LENGTH)*FRAME_SIZE\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    input = self.data[i:i+HISTORY_LENGTH*FRAME_SIZE,:]\n",
        "    label = self.data[i+HISTORY_LENGTH*FRAME_SIZE:i+(HISTORY_LENGTH+PREDICTION_LENGTH)*FRAME_SIZE,:]\n",
        "    # transform\n",
        "    self.transform(input)\n",
        "    self.target_transform(label)\n",
        "    return input, label"
      ],
      "metadata": {
        "id": "jYE0QJ5ljxtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Traces_6DOF_Dataset('/content/drive/MyDrive/Traces_6DOF_NJIT/node2mobility.mat', transform=ToTensor(), target_transform=ToTensor())\n",
        "val_dataset = Traces_6DOF_Dataset('/content/drive/MyDrive/Traces_6DOF_NJIT/node1mobility.mat', transform=ToTensor(), target_transform=ToTensor())\n",
        "test_dataset = Traces_6DOF_Dataset('/content/drive/MyDrive/Traces_6DOF_NJIT/node5mobility.mat', transform=ToTensor(), target_transform=ToTensor())\n",
        "# print(dataset[0])\n",
        "# train_data, test_data = train_test_split_dataset(dataset, test_size=0.25)\n",
        "print(\"train dataset size: \", len(train_dataset))"
      ],
      "metadata": {
        "id": "zVTe3CPwn0Hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5417e2ca-ef3b-42c3-95c2-fb1c9bc3dbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train dataset size:  2625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "q7ESyPBTItXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train data shape[n_batch, seq_len, embedding_size]: \", len(train_dataloader), train_dataset[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KILwd7xWbuSg",
        "outputId": "28839679-7e0b-49ef-8f8d-a2a234982b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape[n_batch, seq_len, embedding_size]:  41 (250, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utilis\n",
        "# checkpointing\n",
        "def save_ckpt(fn, network, optimizer):\n",
        "  torch.save({'net': network.state_dict(), 'opt': optimizer.state_dict()}, fn)\n",
        "\n",
        "def load_ckpt(fn, network, optimizer):\n",
        "  # ckpt = torch.load(fn,map_location=torch.device('cpu'))\n",
        "  ckpt = torch.load(fn)\n",
        "  network.load_state_dict(ckpt['net'])\n",
        "  optimizer.load_state_dict(ckpt['opt'])\n",
        "  return network, optimizer"
      ],
      "metadata": {
        "id": "3QfJeOmEyoLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            batch_first=False\n",
        "        )\n",
        "\n",
        "        self.MLP = nn.Sequential(\n",
        "          nn.Linear(6, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.LayerNorm(64),\n",
        "          nn.Linear(64, 128),\n",
        "          nn.ReLU(embedding_size),\n",
        "          nn.LayerNorm(128),\n",
        "          nn.Linear(128, embedding_size),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_out = nn.Linear(embedding_size, 6)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = torch.Tensor(src.cpu().detach().numpy() == np.zeros((1,embedding_size),float))\n",
        "\n",
        "        # (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N,_ = src.shape\n",
        "        trg_seq_length, N,_ = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        # print(\"src position shape before pos: \", src_positions.shape)\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        embed_src = self.dropout(\n",
        "            self.MLP(src) + self.src_position_embedding(src_positions)\n",
        "        )\n",
        "        # print(\"src: \", src[0][0])\n",
        "        # print(\"position embedding: \", self.src_position_embedding(src_positions)[0][0])\n",
        "        # print(\"embed src: \", embed_src[0][0])\n",
        "        embed_trg = self.dropout(\n",
        "            self.MLP(trg) + self.trg_position_embedding(trg_positions)\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(embed_src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "        # print(\"trg_mask: \", trg_mask)\n",
        "        # print(\"src_mask shape after pos: \", src_padding_mask.shape)\n",
        "        # print(\"trg_mask shape after pos: \", trg_mask.shape)\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            # src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask\n",
        "        )\n",
        "        # print(\"output\", out)\n",
        "        # print(\"output dtype before decode: \", out.dtype)\n",
        "        # print(\"output shape before decode: \", out.shape)\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def encode(self, src: Tensor):\n",
        "        src_seq_length, N, _ = src.shape\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        ) \n",
        "        embed_src = self.MLP(src) + self.src_position_embedding(src_positions)\n",
        "        embed_src = embed_src.to(self.device)\n",
        "        src_padding_mask = self.make_src_mask(embed_src)\n",
        "        return self.transformer.encoder(embed_src, src_padding_mask)\n",
        "\n",
        "    def decode(self, trg: Tensor, memory: Tensor, trg_mask: Tensor):\n",
        "        trg_seq_length, N,_ = trg.shape\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "        embed_trg = self.MLP(trg) + self.trg_position_embedding(trg_positions)\n",
        "        embed_trg = embed_trg.to(self.device)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "        return self.transformer.decoder(embed_trg, memory,\n",
        "                          trg_mask)\n",
        "\n"
      ],
      "metadata": {
        "id": "-wFANikzqmni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ntokens = 256  # embedding dimentsion of coordinates\n",
        "input_size = HISTORY_LENGTH*FRAME_SIZE\n",
        "output_size = PREDICTION_LENGTH*FRAME_SIZE\n",
        "embedding_size = 200 # embedding dimension\n",
        "forward_expansion = 512  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
        "num_heads = 8  # number of heads in ``nn.MultiheadAttention``\n",
        "max_len = HISTORY_LENGTH*FRAME_SIZE\n",
        "dropout = 0.1  # dropout probability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device=DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "lr = LEARNING_RATE  # learning rate\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#     optimizer, factor=0.1, patience=10\n",
        "# )\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "batch_size = BATCH_SIZE\n",
        "epochs = NUM_EPOCHS"
      ],
      "metadata": {
        "id": "kHvviK_zNaW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: nn.Module, data_loader, optimizer, scaler, writer, step) -> None:\n",
        "    progress_bar = tqdm(data_loader)\n",
        "    model.train() # turn on train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    num_batches = len(data_loader)\n",
        "    log_interval = num_batches // 5\n",
        "    return_loss = 0.\n",
        "    for batch_idx, (data, targets) in enumerate(progress_bar):\n",
        "        # print(\"batch index: \", batch_idx)\n",
        "        # change src, tar shape from N,S,E to S,N,E to match batch_first=false\n",
        "        data = data.permute(1, 0, 2)\n",
        "        data = data.to(device=DEVICE)\n",
        "        # print(\"data: \", data.shape)\n",
        "        targets = targets.permute(1, 0, 2)\n",
        "        targets = targets.to(device=DEVICE)\n",
        "        # print(\"targets: \", targets.shape)\n",
        "        # with torch.cuda.amp.autocast():\n",
        "        output = model(data, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, targets)\n",
        "        # print(loss)\n",
        "        # scaler.scale(loss).backward()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        # scaler.step(optimizer)\n",
        "        optimizer.step()\n",
        "        # scaler.update()\n",
        "        writer.add_scalar(\"Training Loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        return_loss += loss.item()\n",
        "        progress_bar.set_postfix_str(f\"training loss={loss.item():.3e}|avg training loss={total_loss/(batch_idx+1):.3e}\")\n",
        "        if batch_idx % log_interval == 0 and batch_idx > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(f'| epoch {epoch:3d} | {batch_idx:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "    return return_loss/(batch_idx+1)\n",
        "\n",
        "def evaluate(model: nn.Module, dataloader: DataLoader) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for (data, targets) in dataloader:\n",
        "            data = data.permute(1, 0, 2)\n",
        "            targets = targets.permute(1, 0, 2)\n",
        "            data = data.to(device=DEVICE)\n",
        "            targets = targets.to(device=DEVICE)\n",
        "\n",
        "            output = model(data, targets)\n",
        "            # output_flat = output.view(-1, output_size)\n",
        "            total_loss += criterion(output, targets).item()\n",
        "            # print(\"val loss: \", total_loss)\n",
        "            # data = data.permute(1, 0, 2) #.detach().cpu().numpy()\n",
        "            # output = output.permute(1, 0, 2) #.detach().cpu().numpy()\n",
        "            # print(\"output2: \", output[0][0])\n",
        "    return total_loss / (len(dataloader) - 1)\n"
      ],
      "metadata": {
        "id": "54tDK9WdOf0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL = False\n",
        "# training\n",
        "if LOAD_MODEL:\n",
        "    load_ckpt(\"/content/drive/MyDrive/checkpoints_new20.pt\", model, optimizer)\n",
        "\n",
        "# with TemporaryDirectory() as tempdir:\n",
        "#     best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "print(scaler)\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "best_val_loss = float('inf')\n",
        "writer = SummaryWriter(\"run/loss_plot\")\n",
        "step = 0\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    print(f'Epoch #{epoch}')\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train(model, train_dataloader, optimizer, scaler, writer, step)\n",
        "    # print(train_loss)\n",
        "    training_loss.append(train_loss)\n",
        "    mean_loss = sum(training_loss)/len(training_loss)\n",
        "    val_loss = evaluate(model, val_dataloader)\n",
        "    validation_loss.append(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "        f'valid loss {mean_loss:5.2f} | mean loss {mean_loss:8.2f}')\n",
        "    print('-' * 89)\n",
        "    if mean_loss < best_val_loss:\n",
        "        best_val_loss = mean_loss\n",
        "        # save model\n",
        "        save_ckpt(\"/content/drive/MyDrive/checkpoints_new20.pt\", model, optimizer)\n",
        "    # scheduler.step(mean_loss)\n",
        "    scheduler.step()\n",
        "# load_ckpt(\"/content/drive/MyDrive/checkpoints.pt\", model, optimizer)\n",
        "      \n"
      ],
      "metadata": {
        "id": "bzC9glrOkNEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input):\n",
        "    model.train()\n",
        "    trg_input = torch.unsqueeze(input[-1], 0)\n",
        "    num_tokens = len(input[0])\n",
        "    for _ in range(0,50):\n",
        "          # Get source mask\n",
        "          trg_mask = model.transformer.generate_square_subsequent_mask(PREDICTION_LENGTH*FRAME_SIZE).to(\n",
        "            DEVICE\n",
        "          )\n",
        "          pred = model(input, trg_input)\n",
        "          # print(pred)\n",
        "          next_item = pred[0] # num with highest probability\n",
        "          next_item = torch.unsqueeze(next_item,0)\n",
        "          trg_input = torch.vstack((trg_input, next_item))\n",
        "    return trg_input[1:]"
      ],
      "metadata": {
        "id": "iKQ6eI48IrGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_arr = []\n",
        "output_arr = []\n",
        "targets_arr = []\n",
        "for (data, targets) in test_dataloader:\n",
        "    input = torch.unsqueeze(data[0],1).to(DEVICE)\n",
        "    target = torch.unsqueeze(targets[0],1).to(DEVICE)\n",
        "    pred = predict(model, input)\n",
        "    input_arr.append(data)\n",
        "    output_arr.append(pred)\n",
        "    targets_arr.append(target)"
      ],
      "metadata": {
        "id": "P2KFJFomKgz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_loss)\n",
        "epochs = range(1, len(training_loss)+1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, torch.tensor(training_loss).numpy(), label='Training Loss')\n",
        "# plt.plot(epochs, torch.tensor(validation_loss).numpy(), label='Validation Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZVpV_npUeE92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaw1 = torch.squeeze(torch.stack(output_arr))[1,:,3].detach().cpu().numpy()*180\n",
        "pitch1 = torch.squeeze(torch.stack(output_arr))[1,:,4].detach().cpu().numpy()*90\n",
        "roll1 = torch.squeeze(torch.stack(output_arr))[1,:,5].detach().cpu().numpy()*90\n",
        "yaw = torch.squeeze(torch.stack(targets_arr))[1,:,3].detach().cpu().numpy()*180\n",
        "pitch = torch.squeeze(torch.stack(targets_arr))[1,:, 4].detach().cpu().numpy()*90\n",
        "roll = torch.squeeze(torch.stack(targets_arr))[1,:, 5].detach().cpu().numpy()*90\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "G = ax.scatter(yaw, pitch, roll, c='g', marker='o')\n",
        "O = ax.scatter(-yaw1, pitch1, roll1, c='y', marker='o')\n",
        "plt.legend((G,O),('Ground truth','Output'))\n",
        "ax.set_xlabel('yaw')\n",
        "ax.set_ylabel('pitch')\n",
        "ax.set_zlabel('roll')\n",
        "plt.show()\n",
        "# fig.savefig('fig/oo_1.png')"
      ],
      "metadata": {
        "id": "vgA2xutKuIgj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}